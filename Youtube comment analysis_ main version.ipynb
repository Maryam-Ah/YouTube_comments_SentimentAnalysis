{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo_3u1xVPmCD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth in /opt/anaconda3/lib/python3.7/site-packages (1.19.2)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/anaconda3/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: google-auth-httplib2 in /opt/anaconda3/lib/python3.7/site-packages (0.0.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth) (49.3.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/anaconda3/lib/python3.7/site-packages (from google-auth) (4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib) (1.3.0)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth-httplib2) (0.18.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth) (0.4.8)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.24.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2019.11.28)\n",
      "Requirement already satisfied: demoji in /opt/anaconda3/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.7/site-packages (from demoji) (0.4.3)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from demoji) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0->demoji) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0->demoji) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0->demoji) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0->demoji) (2019.11.28)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Requirement already satisfied: langdetect in /opt/anaconda3/lib/python3.7/site-packages (1.0.8)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from langdetect) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-auth google-auth-oauthlib google-auth-httplib2\n",
    "!pip install demoji\n",
    "!pip install pandas\n",
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1599665456778,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "eOH9afSPPuNX"
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import pandas as pd\n",
    "import demoji\n",
    "from langdetect import detect\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "import re   # regular expression\n",
    "from textblob import TextBlob\n",
    "from sklearn import metrics\n",
    "# from mlxtend.plotting import plot_confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import pickle \n",
    "import joblib\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1599661396922,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "9cxfE0cMP7Q7"
   },
   "outputs": [],
   "source": [
    "CLIENT_SECRETS_FILE = \"client_secret.json\"\n",
    "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
    "API_SERVICE_NAME = 'youtube'\n",
    "API_VERSION = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1599661405571,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "U0lO965cP9Is"
   },
   "outputs": [],
   "source": [
    "def get_authenticated_service():\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
    "    credentials = flow.run_console()\n",
    "    return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23kQnWjyP_LZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1069387478686-rmblc2j43mb948377962a464m2k83p07.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=wSFujmZlHuAXGUI2KSnjb4LcQqac1s&prompt=consent&access_type=offline\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the authorization code:  4/5AEkvClrWRbtJbo-IQ9SWiMBarUsXA-_Z3XWwfd4AbMFR0JA2_4eQ0g\n"
     ]
    }
   ],
   "source": [
    "# drive.mount('/content/drive')\n",
    "# os.chdir('/content/drive/My Drive/Colab Notebooks/Youtube API')\n",
    "# os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "service = get_authenticated_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1599668206503,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "631jIbS8QBPR"
   },
   "outputs": [],
   "source": [
    "query = \"Coronavirus: Canadian students head back to school in anxious, uncertain times\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz0TT2FhQm0P"
   },
   "source": [
    "PIPLINE =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31166,
     "status": "ok",
     "timestamp": 1599668239340,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "V2FzEDusQlrH",
    "outputId": "f88a0aa2-dee7-43d7-aadd-1d214c1a1381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.20 seconds)\n",
      "Writing emoji data to /Users/maryam/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "query_results = service.search().list(part = 'snippet',q = query,\n",
    "                                      order = 'relevance', \n",
    "                                      type = 'video',\n",
    "                                      relevanceLanguage = 'en',\n",
    "                                      safeSearch = 'moderate').execute()\n",
    "\n",
    "video_id = []\n",
    "channel = []\n",
    "video_title = []\n",
    "video_desc = []\n",
    "for item in query_results['items']:\n",
    "    video_id.append(item['id']['videoId'])\n",
    "    channel.append(item['snippet']['channelTitle'])\n",
    "    video_title.append(item['snippet']['title'])\n",
    "    video_desc.append(item['snippet']['description'])\n",
    "\n",
    "\n",
    "video_id = video_id[0]\n",
    "channel = channel[0]\n",
    "video_title = video_title[0]\n",
    "video_desc = video_desc[0]\n",
    "\n",
    "\n",
    "\n",
    "video_id_pop = []\n",
    "channel_pop = []\n",
    "video_title_pop = []\n",
    "video_desc_pop = []\n",
    "comments_pop = []\n",
    "comment_id_pop = []\n",
    "reply_count_pop = []\n",
    "like_count_pop = []\n",
    "\n",
    "\n",
    "comments_temp = []\n",
    "comment_id_temp = []\n",
    "reply_count_temp = []\n",
    "like_count_temp = []\n",
    "\n",
    "\n",
    "nextPage_token = None\n",
    "\n",
    "while 1:\n",
    "    response = service.commentThreads().list(\n",
    "                    part = 'snippet',\n",
    "                    videoId = video_id,\n",
    "                    maxResults = 100, \n",
    "                    order = 'relevance', \n",
    "                    textFormat = 'plainText',\n",
    "                    pageToken = nextPage_token\n",
    "                    ).execute()\n",
    "\n",
    "\n",
    "    nextPage_token = response.get('nextPageToken')\n",
    "    for item in response['items']:\n",
    "        comments_temp.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "        comment_id_temp.append(item['snippet']['topLevelComment']['id'])\n",
    "        reply_count_temp.append(item['snippet']['totalReplyCount'])\n",
    "        like_count_temp.append(item['snippet']['topLevelComment']['snippet']['likeCount'])\n",
    "        comments_pop.extend(comments_temp)\n",
    "        comment_id_pop.extend(comment_id_temp)\n",
    "        reply_count_pop.extend(reply_count_temp)\n",
    "        like_count_pop.extend(like_count_temp)\n",
    "\n",
    "        video_id_pop.extend([video_id]*len(comments_temp))\n",
    "        channel_pop.extend([channel]*len(comments_temp))\n",
    "        video_title_pop.extend([video_title]*len(comments_temp))\n",
    "        video_desc_pop.extend([video_desc]*len(comments_temp))\n",
    "\n",
    "    if nextPage_token is  None:\n",
    "        break\n",
    "    \n",
    "\n",
    "output_dict = {\n",
    "       'Channel': channel_pop,\n",
    "        'Video Title': video_title_pop,\n",
    "        'Video Description': video_desc_pop,\n",
    "        'Video ID': video_id_pop,\n",
    "        'Comment': comments_pop,\n",
    "        'Comment ID': comment_id_pop,\n",
    "        'Replies': reply_count_pop,\n",
    "        'Likes': like_count_pop,\n",
    "        }\n",
    "\n",
    "output_df = pd.DataFrame(output_dict, columns = output_dict.keys())\n",
    "\n",
    "\n",
    "duplicates = output_df[output_df.duplicated(\"Comment ID\")]\n",
    "\n",
    "\n",
    "unique_df = output_df.drop_duplicates(subset=['Comment'])\n",
    "\n",
    "comments = unique_df\n",
    "\n",
    "demoji.download_codes()\n",
    "\n",
    "comments['clean_comments'] = comments['Comment'].apply(lambda x: demoji.replace(x,\"\"))\n",
    "\n",
    "comments['language'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in range(0,len(comments)):\n",
    "    temp = comments['clean_comments'].iloc[i]\n",
    "    count += 1\n",
    "    try:\n",
    "        comments['language'].iloc[i] = detect(temp)\n",
    "    except:\n",
    "        comments['language'].iloc[i] = \"error\"\n",
    "\n",
    "\n",
    "comments[comments['language']=='en']['language'].value_counts()\n",
    "\n",
    "english_comm = comments[comments['language'] == 'en']\n",
    "\n",
    "en_comments = english_comm\n",
    "\n",
    "regex = r\"[^0-9A-Za-z'\\t]\"\n",
    "\n",
    "copy = en_comments.copy()\n",
    "\n",
    "\n",
    "copy['reg'] = copy['clean_comments'].apply(lambda x:re.findall(regex,x))\n",
    "copy['regular_comments'] = copy['clean_comments'].apply(lambda x:re.sub(regex,\"  \",x))\n",
    "\n",
    "\n",
    "dataset = copy[['Video Title','Video ID','Comment ID','Replies','Likes','regular_comments']].copy()\n",
    "\n",
    "\n",
    "dataset = dataset.rename(columns = {\"regular_comments\":\"comments\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mapnjrG7SBm4"
   },
   "source": [
    "SENTIMENTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1599668015397,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "YSyvEXyuSB7d",
    "outputId": "4aaf77e1-228c-4c0d-acb6-56931bea67b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maryam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/maryam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'online': 1286, 'schooling': 1588, 'fine': 704, 'idea': 913, 'kids': 1009, 'would': 2054, 'log': 1091, '9am': 57, 'able': 60, 'see': 1601, 'teacher': 1811, 'like': 1065, 'classroom': 361, 'taught': 1808, 'home': 888, 'computer': 402, 'oh': 1278, 'covid': 444, 'keeps': 1004, 'spreading': 1714, 'meanwhile': 1150, 'death': 487, 'rate': 1455, 'gone': 799, 'admit': 82, 'seasonal': 1597, 'flu': 717, 'stop': 1739, 'talking': 1801, 'already': 106, 'elaborate': 600, 'hoax': 884, 'everybody': 636, 'half': 831, 'brain': 245, 'knows': 1022, 'lying': 1112, 'heys': 870, 'guys': 827, 'get': 775, 'haha': 829, 'report': 1500, 'bad': 177, 'behaviour': 202, 'mean': 1148, 'people': 1341, 'trying': 1915, 'return': 1523, 'normal': 1253, 'life': 1064, 'say': 1575, 'else': 604, 'yea': 2064, 'sound': 1695, 'fascist': 679, 'nieces': 1247, 'nephews': 1235, 'saint': 1560, 'petersburg': 1351, 'florida': 716, 'ca': 282, 'wait': 1977, 'move': 1202, 'new': 1240, 'brunswick': 267, 'go': 790, 'class': 358, 'school': 1585, 'wife': 2020, 'children': 342, 'aid': 98, 'case': 307, 'worker': 2045, 'want': 1985, 'back': 174, 'union': 1933, 'attack': 162, 'taxpayers': 1809, 'disgrace': 537, 'trudeau': 1911, 'communist': 392, 'gov': 803, 'right': 1533, 'make': 1119, 'rules': 1549, 'laws': 1035, 'emegency': 606, 'ask': 154, 'lawyer': 1037, 'treating': 1900, 'criminals': 460, 'freedom': 744, 'manitoba': 1126, 'politicians': 1378, 'legislature': 1051, 'another': 124, 'month': 1196, 'cowards': 446, 'throw': 1854, 'bus': 276, 'adult': 83, 'met': 1166, 'test': 1828, 'safety': 1557, 'protocols': 1424, 'douge': 565, 'ford': 730, 'balls': 179, 'steel': 1733, 'good': 800, 'could': 434, 'homeschooled': 889, 'one': 1284, 'thing': 1840, 'upset': 1943, 'masks': 1138, 'day': 481, 'hard': 844, 'breath': 252, 'think': 1842, 'harder': 845, 'learn': 1044, 'stay': 1729, 'feet': 692, 'apart': 135, 'teachers': 1812, 'heir': 862, 'also': 107, 'kid': 1008, 'sick': 1646, 'every': 635, 'child': 340, 'tested': 1829, 'understandable': 1928, '14': 10, 'days': 482, 'wish': 2031, 'schools': 1589, 'canada': 293, 'learning': 1045, 'slows': 1670, 've': 1962, 'called': 288, 'police': 1375, 'party': 1325, 'illegally': 922, 'done': 557, 'sarcastic': 1566, 'response': 1510, 'pulling': 1434, 'officers': 1275, 'yet': 2073, 'shooting': 1635, 'told': 1871, 'desk': 513, 'officer': 1274, 'taking': 1799, 'care': 303, 'call': 287, 'going': 797, 'damage': 474, 'tell': 1820, 'public': 1433, 'wo': 2036, 'answer': 125, 'respond': 1509, 'duty': 577, 'pfttttt': 1352, 'nothing': 1258, 'well': 2012, 'midnight': 1171, 'noise': 1251, 'complaint': 397, 'rather': 1456, 'concern': 403, 'jesus': 987, 'coming': 385, 'doctors': 550, 'scientist': 1591, 'mad': 1113, 'cases': 309, 'sea': 1595, 'millions': 1177, 'watching': 1998, 'take': 1798, 'guise': 825, 'virus': 1969, 'wake': 1980, 'welp': 2013, 'im': 923, 'ontario': 1288, 'imma': 926, 'die': 520, 'less': 1053, 'covid9': 445, '11': 6, 'inside': 962, 'job': 990, 'realize': 1465, 'many': 1130, 'absolute': 63, 'nutjobs': 1266, 'read': 1462, 'global': 784, 'cbc': 319, 'comment': 387, 'sections': 1600, 'seriously': 1621, 'come': 379, 'hell': 863, 'accepting': 69, 'bill': 221, 'gates': 764, 'money': 1192, 'canadians': 295, 'terrorism': 1827, 'damn': 475, 'know': 1018, '90': 56, 'false': 672, 'positives': 1385, 'fear': 685, 'mongering': 1193, 'finest': 706, '185': 23, 'province': 1430, 'million': 1176, 'squeal': 1717, 'neighbours': 1234, 'message': 1164, 'unreal': 1937, 'everyone': 638, 'eventually': 633, 'avoiding': 169, 'eventuality': 632, 'causing': 318, 'way': 2001, 'harm': 846, 'living': 1081, 'regular': 1486, 'lives': 1080, 'cant': 298, 'hangout': 839, 'friends': 751, 'tho': 1845, 'least': 1046, 'togethor': 1869, 'meet': 1158, 'fact': 665, 'trust': 1912, 'lord': 1099, 'christ': 348, 'saved': 1572, 'pandemic': 1311, 'us': 1946, 'anxious': 128, 'parents': 1319, 'terrified': 1826, 'watch': 1997, 'marxist': 1134, 'propaganda': 1412, 'network': 1238, 'spews': 1706, 'daily': 473, 'enemy': 615, 'canadian': 294, 'unions': 1934, 'need': 1228, 'reason': 1467, 'thank': 1834, 'god': 792, 'decided': 491, 'daughter': 479, 'asthma': 158, 'greater': 817, 'risk': 1539, 'hey': 869, 'sorry': 1694, 'hear': 855, 'still': 1735, 'getting': 777, 'infected': 954, 'crime': 457, 'wear': 2004, 'mask': 1135, 'made': 1114, 'plan': 1363, 'let': 1056, 'ego': 598, 'basically': 186, 'especially': 625, 'better': 212, 'education': 591, 'clear': 365, 'glass': 783, 'plastic': 1366, 'area': 142, 'student': 1752, 're': 1459, 'purifier': 1439, 'heads': 852, 'ac': 65, 'head': 850, 'grade': 810, 'talk': 1800, 'eachother': 580, 'opens': 1292, 'speakers': 1701, 'indivially': 948, 'boxed': 242, 'bathroom': 189, 'leading': 1043, 'outside': 1304, 'parent': 1318, 'pick': 1356, 'legit': 1052, 'forgot': 735, 'time': 1862, 'news': 1242, 'channels': 330, 'actually': 78, 'used': 1949, 'likes': 1067, 'dislikes': 543, 'normally': 1254, 'abuse': 64, 'wearing': 2005, 'touch': 1879, 'face': 663, 'dirty': 526, 'whatever': 2015, 'leftist': 1050, 'complain': 395, 'supporting': 1773, 'uncharted': 1924, 'times': 1863, 'become': 194, 'political': 1377, 'issue': 981, 'disgusted': 538, 'banging': 180, 'government': 805, 'wonder': 2039, 'worried': 2049, 'mixed': 1189, 'messages': 1165, 'stress': 1746, 'families': 673, 'contracted': 421, 'peak': 1336, 'summer': 1769, 'end': 611, 'world': 2048, 'recovery': 1474, 'dr': 566, 'tom': 1872, 'adam': 80, 'apple': 139, 'third': 1844, 'wave': 2000, 'start': 1723, 'democrats': 502, 'lose': 1100, 'ever': 634, 'since': 1657, 'war': 1987, 'wars': 1991, 'ended': 613, 'creating': 453, 'problems': 1403, 'planet': 1365, 'different': 523, 'kinda': 1013, 'old': 1280, 'white': 2017, 'women': 2038, 'got': 802, 'ta': 1791, 'send': 1611, 'walking': 1981, '100': 4, 'science': 1590, 'side': 1648, 'uncertain': 1923, 'sitting': 1661, 'hands': 837, 'long': 1094, 'instead': 965, 'pay': 1332, 'incompetence': 938, 'guess': 824, 'solution': 1685, 'left': 1049, 'wing': 2025, 'protests': 1422, 'violence': 1967, 'bomb': 233, 'explosions': 656, 'happening': 841, 'around': 144, 'pandmeic': 1313, 'waiting': 1979, 'vaccine': 1956, 'food': 723, 'telling': 1821, 'thought': 1848, 'work': 2044, 'hospital': 893, 'probably': 1401, 'zero': 2077, 'parties': 1323, 'family': 674, 'gatherings': 766, 'opening': 1291, 'filled': 701, 'hundreds': 907, 'hours': 898, 'country': 436, 'run': 1550, 'idiots': 915, 'globalist': 786, 'pretty': 1396, 'sure': 1778, 'last': 1032, 'december': 489, 'even': 631, 'knew': 1015, 'mildly': 1174, 'fever': 693, 'bronchitis': 262, 'symptoms': 1788, 'said': 1559, 'anything': 131, 'hope': 891, 'lol': 1093, 'haunt': 849, 'ccp': 320, 'affecting': 88, 'immune': 929, 'systems': 1790, 'please': 1370, 'ppl': 1388, 'vulnerable': 1975, 'diseases': 536, '42': 43, 'lovely': 1104, 'week': 2010, 'seen': 1605, 'bare': 182, 'brampton': 248, 'dont': 558, 'spread': 1713, 'exempt': 648, 'comply': 401, 'control': 422, 'rocco': 1544, 'galati': 761, 'toronto': 1876, 'lawyernis': 1038, 'using': 1951, 'tam': 1803, 'rest': 1513, 'evil': 643, 'bastards': 188, 'wins': 2026, 'gon': 798, 'na': 1217, 'give': 779, 'elderly': 601, 'shots': 1640, 'year': 2066, 'blame': 225, 'joke': 993, 'wipes': 2029, 'top': 1874, 'soon': 1693, 'henry': 867, 'criminal': 459, 'punished': 1435, 'crimes': 458, 'lockdown': 1087, 'reduce': 1476, 'rofl': 1545, 'ai': 97, 'away': 170, 'prepare': 1391, 'health': 853, 'system': 1789, 'course': 439, 'll': 1082, 'keep': 1002, 'moving': 1206, 'forward': 737, 'live': 1077, 'wow': 2056, 'lucky': 1109, 'bc': 191, 'etc': 628, 'hate': 848, 'print': 1397, 'ad': 79, 'nauseum': 1225, 'economy': 589, 'running': 1551, 'suggests': 1765, 'efficient': 595, 'enough': 619, 'mechanized': 1153, 'warrant': 1989, 'full': 754, 'universal': 1935, 'basic': 185, 'income': 936, 'tasking': 1806, 'sister': 1659, 'started': 1724, 'today': 1866, 'temperature': 1822, 'screen': 1592, 'omg': 1283, 'torture': 1877, 'continues': 419, 'population': 1382, 'via': 1964, 'put': 1442, 'measures': 1151, 'protect': 1419, 'feel': 691, 'graduate': 812, 'lack': 1028, 'respect': 1508, 'real': 1464, 'believe': 207, 'garbage': 763, 'remote': 1494, 'session': 1623, 'anywhere': 134, 'logical': 1092, 'select': 1606, 'handful': 836, 'representative': 1505, 'sample': 1563, 'urban': 1945, 'small': 1671, 'town': 1884, 'rural': 1553, 'open': 1289, 'seven': 1624, 'weeks': 2011, 'closely': 370, 'monitor': 1194, 'tests': 1832, 'students': 1753, 'rigorous': 1535, 'documentation': 551, 'variations': 1961, 'procedures': 1404, 'equally': 623, 'plausible': 1367, 'ones': 1285, 'incorporated': 939, 'experiment': 653, 'selected': 1607, 'volunteer': 1973, 'inclined': 934, 'particular': 1322, 'burden': 275, 'risks': 1541, 'best': 210, 'methodology': 1167, 'evidence': 642, 'warrants': 1990, 'apply': 140, 'knowledge': 1020, 'general': 769, 'reopening': 1497, 'works': 2047, 'policy': 1376, 'much': 1209, 'china': 344, 'highlighted': 876, 'reply': 1499, 'harold': 847, 'ago': 95, 'flesh': 713, 'son': 1690, 'joshua': 994, 'koenig': 1023, '1for': 27, 'ye': 2063, 'great': 816, 'conflict': 408, 'laodicea': 1029, '2that': 36, 'hearts': 859, 'might': 1173, 'comforted': 383, 'knit': 1016, 'together': 1867, 'love': 1103, 'unto': 1940, 'riches': 1528, 'assurance': 157, 'understanding': 1929, 'acknowledgement': 74, 'mystery': 1215, 'father': 682, '3in': 41, 'hid': 871, 'treasures': 1899, 'wisdom': 2030, '4and': 45, 'lest': 1055, 'man': 1123, 'beguile': 200, 'enticing': 620, 'words': 2043, '5for': 50, 'though': 1847, 'absent': 62, 'spirit': 1708, 'joying': 995, 'beholding': 205, 'order': 1296, 'stedfastness': 1732, 'faith': 668, '159': 13, 'matter': 1144, 'human': 904, 'mistakes': 1187, 'suffer': 1762, '160': 14, 'john': 992, '1st': 29, 'verse': 1963, 'bibles': 216, 'beginning': 198, 'word': 2041, 'look': 1096, '161': 15, '14th': 11, 'dwelt': 578, 'among': 117, 'beheld': 203, 'glory': 789, 'begotten': 199, 'grace': 809, 'truth': 1914, '162': 16, 'something': 1689, 'holy': 887, 'must': 1212, 'ordained': 1295, '163': 17, 'farther': 677, 'mentally': 1161, 'speaking': 1702, 'star': 1722, 'fore': 731, 'sun': 1770, 'moon': 1198, 'creation': 454, 'congregation': 410, 'says': 1577, 'amen': 111, 'ed': 590, 'far': 676, '164': 18, '165': 19, 'catholic': 313, 'thoughts': 1849, 'eternal': 629, 'sonship': 1692, 'born': 237, '166': 20, 'wind': 2024, 'ourself': 1302, 'scripture': 1593, '167': 21, 'earth': 582, 'marvelous': 1133, 'sin': 1656, '54': 48, '1003m': 5, 'became': 193, 'india': 945, 'trip': 1907, 'rev': 1525, 'william': 2022, 'marrion': 1132, 'branham': 249, 'fast': 680, 'sounds': 1697, 'big': 218, 'deal': 485, 'huge': 903, 'unfortunately': 1931, 'diligent': 524, 'means': 1149, 'forcing': 729, 'force': 727, 'including': 935, 'officials': 1276, 'sit': 1660, 'ivory': 985, 'towers': 1883, 'lot': 1102, 'stressful': 1747, 'keeping': 1003, 'yes': 2071, 'safer': 1556, 'smaller': 1672, 'sizes': 1665, 'period': 1344, 'rethink': 1521, 'everyday': 637, 'evolution': 644, 'starting': 1725, 'dying': 579, 'turn': 1916, 'trigger': 1905, 'change': 328, 'districts': 548, 'dedicated': 493, 'liking': 1068, 'future': 759, 'point': 1372, 'dead': 483, 'theres': 1838, 'giving': 781, 'gratful': 815, 'questioning': 1447, 'closed': 369, 'opened': 1290, '400': 42, 'plus': 1371, '30': 39, 'gets': 776, 'cold': 375, 'media': 1154, 'blows': 230, 'proportion': 1415, 'wasted': 1996, 'registration': 1483, 'simple': 1654, 'lived': 1078, 'forever': 732, '2week': 37, 'complete': 398, 'classes': 359, 'require': 1506, 'physical': 1354, 'presence': 1394, 'function': 757, 'manufacturing': 1129, 'physically': 1355, 'snitch': 1680, 'finish': 707, '6th': 52, 'beer': 196, 'boy': 243, 'trapnell': 1895, 'elementary': 603, 'little': 1076, 'brother': 265, 'without': 2033, 'coronavirus': 426, 'sons': 1691, 'crying': 464, 'yelling': 2069, 'young': 2075, 'tie': 1858, 'shoes': 1633, 'untied': 1939, 'help': 864, 'packages': 1308, 'lunch': 1110, 'straight': 1743, 'ahead': 96, 'yelled': 2068, 'classmate': 360, '12': 8, 'behavior': 201, 'choose': 347, 'scrolling': 1594, 'comments': 388, 'amidst': 115, 'remember': 1492, 'shall': 1626, 'pass': 1327, 'loves': 1105, 'desires': 512, 'relationship': 1487, 'bless': 226, 'plandemic': 1364, 'months': 1197, 'play': 1368, 'aged': 93, 'schooled': 1587, 'anyway': 132, 'indoctrination': 951, 'center': 324, 'cultivation': 466, 'swing': 1785, 'wrath': 2057, 'cancel': 296, 'everything': 640, '17': 22, 'smallest': 1673, 'hallway': 834, 'luck': 1108, 'rise': 1538, 'obviously': 1268, 'proves': 1427, 'piece': 1358, 'cloth': 373, 'molecular': 1190, 'sized': 1664, 'non': 1252, 'medical': 1156, 'packaging': 1309, 'thanks': 1835, 'captain': 301, 'obvious': 1267, 'largely': 1031, 'unknown': 1936, 'affects': 89, 'survivors': 1781, 'discovered': 531, 'fill': 700, 'classrooms': 362, 'capacity': 299, 'educational': 592, 'alternatives': 109, 'protection': 1421, 'arrives': 147, 'simply': 1655, 'irresponsible': 977, 'shut': 1644, 'social': 1682, 'distancing': 547, 'number': 1262, 'high': 874, 'curve': 468, 'shows': 1643, 'worse': 2052, 'annual': 123, 'backed': 175, 'cdc': 322, 'thousands': 1850, 'experts': 655, 'stupid': 1757, 'tactics': 1795, 'transmission': 1893, 'protecting': 1420, 'anyone': 130, 'msm': 1208, 'saying': 1576, 'folks': 719, 'television': 1819, 'italian': 983, 'discovery': 532, 'broke': 261, 'autopsy': 168, 'patient': 1330, 'died': 521, 'corona': 425, 'found': 738, 'bacterial': 176, 'caused': 316, 'blood': 229, 'clot': 372, 'mister': 1188, 'defeated': 495, 'three': 1853, 'power': 1386, 'taste': 1807, 'doug': 564, 'wedding': 2008, 'save': 1571, 'ready': 1463, 'praise': 1389, 'safe': 1555, 'putting': 1444, 'drivers': 570, 'retirees': 1522, 'disinfectant': 541, 'spray': 1711, 'handsanitizer': 838, 'hand': 835, 'pink': 1359, 'slips': 1669, 'ive': 984, 'past': 1328, 'really': 1466, 'tired': 1864, 'barely': 183, 'homework': 890, 'low': 1107, 'affected': 87, 'carriers': 306, 'till': 1861, 'older': 1281, 'grandparents': 814, 'ing': 959, 'sue': 1761, 'file': 698, 'action': 76, 'law': 1034, 'suits': 1768, 'break': 250, 'spell': 1704, 'create': 450, 'fake': 670, 'outbreak': 1303, 'thumb': 1856, 'nail': 1218, 'hair': 830, 'nets': 1237, 'highly': 877, 'inaccurate': 933, 'likely': 1066, 'common': 390, 'colds': 376, 'asymptomatic': 160, 'hysteria': 911, 'communism': 391, 'ashamed': 151, 'article': 149, '1945': 26, 'imt': 932, 'charter': 335, 'nuremberg': 1264, 'codes': 374, 'provides': 1429, 'following': 720, 'acts': 77, 'within': 2032, 'jurisdiction': 998, 'tribunal': 1903, 'individual': 949, 'responsibility': 1511, 'humanity': 905, 'namely': 1220, 'inhumane': 960, 'committed': 389, 'civilian': 355, 'invented': 972, 'cia': 350, 'technique': 1816, '70': 53, 'years': 2067, 'brainwashing': 247, 'forced': 728, 'inoculations': 961, 'occult': 1269, 'symbol': 1787, 'submission': 1759, 'master': 1141, 'necessary': 1227, 'buddy': 268, 'belong': 208, 'prison': 1398, 'bunch': 274, 'liars': 1059, 'bars': 184, 'anyways': 133, 'spraying': 1712, 'bio': 222, 'weapon': 2003, 'second': 1598, 'incoming': 937, 'disaster': 529, 'biblical': 217, 'proportions': 1416, 'smell': 1676, '2nd': 35, 'viruses': 1970, 'body': 232, 'contagious': 417, 'never': 1239, 'proven': 1425, 'nut': 1265, 'jobs': 991, 'vancouver': 1960, 'british': 259, 'columbia': 378, 'encounter': 608, 'spend': 1705, 'mindful': 1179, 'others': 1301, 'clean': 363, 'glad': 782, 'dropped': 571, 'literally': 1075, 'cares': 305, 'lost': 1101, 'september': 1618, 'often': 1277, 'breathing': 254, 'stomach': 1737, '19': 25, 'percent': 1342, 'supposedly': 1776, 'original': 1300, 'numbers': 1263, 'emergency': 607, 'grab': 808, 'either': 599, 'threatened': 1851, 'bribed': 255, 'blackmailed': 224, 'korea': 1025, 'shortage': 1637, 'ordering': 1297, 'dogs': 555, 'meat': 1152, 'starts': 1726, 'comfy': 384, 'happen': 840, 'mindset': 1181, 'fight': 695, 'rights': 1534, 'troll': 1908, 'trolls': 1909, 'comes': 381, 'knocking': 1017, 'door': 561, 'dog': 554, 'herd': 868, 'immunity': 930, 'developing': 517, 'yeah': 2065, 'testing': 1831, 'positive': 1384, 'reporting': 1503, 'deaths': 488, 'hospitalizations': 894, 'ridiculous': 1531, 'compliance': 400, 'masking': 1137, 'looked': 1097, '7888': 54, 'apparently': 137, 'confirmed': 407, 'terminally': 1824, 'ill': 920, 'calculated': 285, 'incorrectly': 940, 'someone': 1688, 'heart': 857, 'later': 1033, 'count': 435, 'towards': 1882, 'counts': 437, 'uses': 1950, 'lead': 1041, 'blind': 227, 'driven': 569, 'frenzy': 748, 'hypocrisy': 910, 'ideas': 914, 'personally': 1349, 'state': 1728, 'worst': 2053, 'punishment': 1436, 'self': 1608, 'isolate': 978, 'worries': 2050, 'next': 1244, 'preschool': 1393, '20': 30, 'olds': 1282, 'foot': 726, 'staff': 1718, 'came': 291, 'knowing': 1019, 'imagine': 925, 'five': 709, 'definitely': 497, 'powers': 1387, 'locked': 1088, 'effectively': 594, 'destroyed': 516, 'economies': 588, 'livelihoods': 1079, '80': 55, 'yrs': 2076, '0000267': 2, 'chance': 327, 'demic': 500, 'pushing': 1441, 'carefully': 304, 'crafted': 447, 'charade': 332, 'phase': 1353, 'shortages': 1638, 'regional': 1482, 'famines': 675, 'casue': 310, 'mainstream': 1117, 'sources': 1699, 'confirm': 406, 'mail': 1116, 'everyones': 639, 'seniors': 1614, 'tough': 1881, 'kindergartners': 1014, 'use': 1948, 'google': 801, '50': 46, 'notice': 1259, 'changed': 329, 'wording': 2042, 'longer': 1095, 'flatting': 712, 'known': 1021, 'humans': 906, 'contract': 420, 'four': 739, 'sars': 1567, 'mers': 1162, 'cov': 440, 'aka': 99, 'maybe': 1147, 'boost': 236, 'baby': 172, 'fall': 671, 'kicks': 1007, 'season': 1596, 'hits': 882, 'fully': 755, 'happy': 843, 'walmart': 1982, 'buy': 281, 'toilet': 1870, 'paper': 1315, 'cheers': 337, 'mud': 1210, 'flinging': 714, 'begin': 197, 'mamma': 1122, 'pappa': 1317, 'forget': 734, 'beings': 206, 'earthu': 583, 'deserve': 511, 'arrested': 145, 'thrown': 1855, 'cage': 284, 'stood': 1738, 'close': 368, 'person': 1347, 'grocery': 818, 'shop': 1636, 'line': 1071, 'tables': 1793, 'chairs': 326, 'restaurants': 1514, 'sense': 1615, 'supposed': 1775, 'helping': 865, 'saftey': 1558, 'reasons': 1468, 'dishing': 540, 'fines': 705, 'acting': 75, 'dumb': 574, 'strict': 1748, 'babying': 173, 'dealt': 486, 'serious': 1620, 'caught': 314, 'jail': 986, 'slap': 1666, 'cut': 469, 'thier': 1839, 'needs': 1229, 'consequences': 411, 'lazy': 1040, 'mutating': 1213, 'becoming': 195, 'smarter': 1675, 'wipe': 2028, 'kind': 1012, 'kill': 1010, 'thompson': 1846, 'twins': 1919, 'lies': 1063, 'first': 708, 'history': 880, 'lessons': 1054, '48': 44, 'childrens': 343, 'fault': 683, 'figured': 697, 'disgusting': 539, 'view': 1966, 'tv': 1918, 'masked': 1136, 'sad': 1554, 'midst': 1172, 'profit': 1407, 'earned': 581, 'working': 2046, 'investing': 974, 'forex': 733, 'trading': 1888, 'expertise': 654, 'mr': 1207, 'andy': 120, 'calistoga': 286, 'valuable': 1959, 'nice': 1245, 'yesterday': 2072, 'preparing': 1392, 'worry': 2051, 'mom': 1191, 'nobody': 1250, 'emailing': 605, 'schoolboard': 1586, '9th': 58, 'english': 616, 'anxiety': 127, 'puts': 1443, 'mouth': 1201, 'nose': 1256, 'okay': 1279, 'noses': 1257, 'reminder': 1493, 'ninth': 1249, 'graders': 811, 'fed': 689, 'french': 747, 'shares': 1627, 'supplies': 1771, 'papers': 1316, 'gives': 780, 'row': 1546, 'touching': 1880, 'markers': 1131, 'sharpeners': 1628, 'pencils': 1340, 'allowed': 102, 'bring': 257, 'goddamn': 793, 'materials': 1142, 'math': 1143, 'lets': 1057, 'desks': 514, '15': 12, 'minutes': 1184, 'finally': 702, 'decides': 492, 'cleanest': 364, 'despite': 515, '13': 9, 'chromebook': 349, 'showing': 1642, 'completely': 399, 'horrible': 892, 'according': 71, 'chemo': 338, 'excused': 647, 'stories': 1741, 'men': 1159, 'dementia': 499, 'caps': 300, 'riot': 1536, 'name': 1219, 'justice': 999, 'effect': 593, 'fighting': 696, 'racism': 1449, 'liberals': 1060, 'charge': 333, 'conservatives': 412, 'facts': 666, 'ignored': 918, 'bro': 260, 'americans': 114, 'travelling': 1897, 'seek': 1602, 'refugee': 1480, 'usa': 1947, 'gta': 822, 'medias': 1155, 'frequently': 749, 'remove': 1495, 'freedoms': 745, 'generations': 771, 'madness': 1115, 'ruining': 1548, 'ont': 1287, 'racken': 1450, 'points': 1373, 'funny': 758, 'cause': 315, 'willing': 2023, 'deadly': 484, 'swear': 1782, 'jump': 996, 'bridge': 256, 'abolish': 61, 'corporation': 427, 'corporations': 428, 'betterment': 213, 'niece': 1246, 'sent': 1617, 'picture': 1357, 'wears': 2006, 'add': 81, 'title': 1865, 'goes': 796, 'extra': 660, 'drama': 567, 'clicks': 366, 'increased': 941, 'reduced': 1477, 'brought': 266, 'terrible': 1825, 'overwhelmed': 1307, 'amount': 118, 'significant': 1651, 'information': 957, 'uts': 1952, 'shot': 1639, 'show': 1641, 'created': 451, 'problem': 1402, 'expect': 652, 'heard': 856, 'n95': 1216, 'slightly': 1668, 'breaking': 251, 'mortality': 1199, 'recognizing': 1472, 'equate': 624, 'therefore': 1837, 'studies': 1754, 'recent': 1471, 'ucla': 1921, 'stanford': 1721, 'provided': 1428, 'data': 478, 'claim': 356, 'narrative': 1222, 'appears': 138, 'angle': 121, 'disable': 527, 'reflect': 1479, 'opinion': 1293, 'indicates': 946, 'support': 1772, 'wildly': 2021, 'exaggerating': 646, 'severity': 1625, 'newsflash': 1243, 'satanic': 1569, 'agenda': 94, 'push': 1440, 'forth': 736, 'mandatory': 1124, 'vaccines': 1957, 'depopulate': 507, 'scare': 1580, 'easier': 584, 'manipulate': 1125, 'reports': 1504, '60': 51, 'received': 1470, 'waste': 1995, 'copy': 424, 'taiwan': 1797, 'democratic': 501, 'places': 1362, 'asia': 152, 'crush': 463, 'penalties': 1339, 'halfway': 832, 'riding': 1532, 'train': 1891, 'pretending': 1395, 'shi': 1630, 'ur': 1944, 'scared': 1581, 'sake': 1561, 'winter': 2027, 'nowhere': 1261, 'survive': 1780, 'hot': 896, 'weather': 2007, 'certain': 325, 'temperatures': 1823, 'isolation': 979, 'periods': 1345, 'malicious': 1121, 'find': 703, 'faithfully': 669, 'immerse': 928, 'exactly': 645, 'minds': 1180, 'spot': 1709, 'deceptions': 490, 'discerning': 530, 'seeks': 1603, 'fool': 724, 'feeds': 690, 'folly': 722, 'proverbs': 1426, 'eyes': 662, 'wander': 1984, 'ends': 614, '24': 32, 'youn': 2074, 'pure': 1438, 'stray': 1744, 'commands': 386, 'hidden': 872, 'psalm': 1431, '119': 7, 'extend': 659, 'loan': 1084, 'sending': 1612, 'hmmm': 883, 'discussed': 533, 'validation': 1958, 'looking': 1098, 'rna': 1542, 'impossible': 931, 'assign': 156, 'infection': 955, '2y': 38, 'type': 1920, 'geno': 772, 'sequence': 1619, 'ccpvirus': 321, 'chinese': 345, 'quebec': 1446, 'higher': 875, 'cover': 441, 'runny': 1552, 'interested': 970, 'sicknesses': 1647, 'labeled': 1027, 'tiered': 1859, 'entire': 621, 'neighborhood': 1232, 'surrounded': 1779, 'jungle': 997, 'gym': 828, 'house': 899, 'saskatchewan': 1568, 'section': 1599, 'grow': 820, 'warned': 1988, 'spike': 1707, 'defund': 498, 'prosecute': 1417, 'frauds': 741, 'kick': 1006, 'govt': 807, 'indict': 947, 'encourage': 610, 'neighbors': 1233, 'rat': 1454, 'lay': 1039, 'charges': 334, 'illegal': 921, 'lawsuit': 1036, 'filed': 699, 'check': 336, 'david': 480, 'icke': 912, 'indeed': 944, 'east': 585, 'germany': 774, 'stasi': 1727, 'promoting': 1411, 'spying': 1716, 'togetherness': 1868, 'citizen': 353, 'spy': 1715, 'suppossed': 1777, 'partys': 1326, 'makes': 1120, 'facing': 664, 'locust': 1090, 'pollution': 1380, 'bird': 223, 'swine': 1784, 'uncontrollable': 1926, 'overpopulation': 1306, 'massive': 1140, 'flooding': 715, 'corrupt': 430, 'jittery': 988, 'restive': 1515, 'angry': 122, 'range': 1452, 'military': 1175, 'conflicts': 409, 'simmering': 1653, 'arrogant': 148, 'north': 1255, 'suggest': 1764, 'unclear': 1925, 'documented': 552, 'adults': 84, 'infrequent': 958, 'american': 113, 'academy': 67, 'pediatrics': 1338, 'aug': 165, '2020': 31, 'achieved': 73, 'maximum': 1145, 'stoked': 1736, 'astrazeneca': 159, 'trial': 1902, 'hold': 885, 'adverse': 85, 'reactions': 1461, 'six': 1663, 'gee': 768, '545': 49, '189': 24, 'crazy': 449, 'rain': 1451, '29': 34, 'covering': 443, 'guy': 826, 'vunerable': 1976, 'wtaf': 2061, 'private': 1399, 'property': 1414, 'suck': 1760, 'guaranteed': 823, 'trouble': 1910, 'fraudulent': 742, 'broscience': 264, 'car': 302, 'accidents': 70, 'smoking': 1678, 'cigarettes': 351, 'regula': 1485, 'flus': 718, 'drinking': 568, 'drug': 572, 'fk': 711, 'sends': 1613, 'investigate': 973, 'corruption': 432, 'scam': 1578, 'brooo': 263, 'afraid': 91, 'bull': 273, 'sweden': 1783, 'didnt': 519, 'similar': 1652, 'killed': 1011, 'business': 278, 'hindered': 879, 'personal': 1348, 'growth': 821, 'listening': 1074, 'paid': 1310, 'whyyyyyy': 2019, 'spotted': 1710, 'wouldnt': 2055, 'wasnt': 1994, 'understand': 1927, 'somebody': 1687, 'cuz': 470, 'ctv': 465, 'wuhan': 2062, 'credibility': 456, 'turning': 1917, 'citizens': 354, 'asked': 155, 'sneezing': 1679, 'coughing': 433, 'headache': 851, 'reach': 1460, 'locking': 1089, 'large': 1030, 'indoor': 952, 'store': 1740, 'follows': 721, 'protocol': 1423, 'community': 393, 'lock': 1086, 'richmond': 1529, 'reporters': 1502, 'front': 753, 'camera': 292, 'shield': 1631, 'specially': 1703, 'contact': 416, 'moved': 1203, 'newfoundland': 1241, 'alberta': 100, 'november': 1260, '25': 33, 'casedemic': 308, 'thats': 1836, 'track': 1887, 'disease': 535, 'choice': 346, 'whether': 2016, 'prefer': 1390, 'risking': 1540, 'perverts': 1350, 'always': 110, 'went': 2014, 'quit': 1448, 'highschool': 878, 'college': 377, 'uni': 1932, 'ammount': 116, 'scary': 1584, 'koolaid': 1024, 'peaple': 1337, 'juuling': 1000, 'washrooms': 1993, 'threatening': 1852, 'poor': 1381, 'breathe': 253, 'issues': 982, 'solve': 1686, 'ruff': 1547, 'payed': 1333, 'issiue': 980, 'departmant': 503, 'alot': 105, 'departmants': 504, 'field': 694, 'parts': 1324, 'instance': 964, 'bank': 181, 'resturant': 1517, 'grogery': 819, 'covered': 442, 'sides': 1649, 'relize': 1490, 'resurant': 1519, 'bigger': 219, 'unsafe': 1938, 'may': 1146, 'trees': 1901, 'building': 271, 'depends': 506, 'location': 1085, 'wrecking': 2058, 'stuff': 1756, 'build': 270, 'hurt': 908, 'built': 272, 'part': 1320, 'limit': 1069, 'causeing': 317, 'serviceing': 1622, 'espoused': 626, 'resurants': 1520, 'distanceing': 546, 'expoused': 658, 'waiters': 1978, 'testers': 1830, 'dang': 476, 'fun': 756, 'beside': 209, 'friend': 750, 'anymore': 129, 'dislike': 542, 'total': 1878, 'failure': 667, 'fatal': 681, 'properly': 1413, 'smh': 1677, 'tear': 1815, '00': 0, 'calm': 290, 'heavens': 860, 'teaching': 1813, 'asinine': 153, 'tantamount': 1804, 'mass': 1139, 'catching': 311, 'cancer': 297, 'sane': 1564, 'mind': 1178, 'utterly': 1953, 'irrational': 976, 'psychological': 1432, 'evaluations': 630, 'nervous': 1236, 'listen': 1073, 'fraud': 740, 'goebbels': 795, 'biggest': 220, 'infections': 956, 'essential': 627, 'refer': 1478, 'doctor': 549, 'atlas': 161, 'loving': 1106, 'trusting': 1913, 'letting': 1058, 'restrict': 1516, 'senses': 1616, 'things': 1841, 'interest': 969, 'mentality': 1160, 'abducted': 59, 'trafficked': 1889, 'vir': 1968, 'minuscule': 1183, 'payroll': 1334, 'hence': 866, 'books': 235, 'almost': 103, 'reported': 1501, 'basis': 187, 'bodies': 231, 'streets': 1745, 'genuinely': 773, 'comedy': 380, 'playlist': 1369, 'stayed': 1730, 'majority': 1118, 'lied': 1062, 'sigh': 1650, 'relief': 1489, 'limited': 1070, 'selfish': 1609, 'chaos': 331, 'mess': 1163, 'lmaoo': 1083, 'video': 1965, 'apologising': 136, 'from': 752, 'bottom': 240, 'dumbest': 575, 'approaching': 141, 'perfect': 1343, 'opportunity': 1294, 'regualr': 1484, 'happens': 842, 'arent': 143, 'fools': 725, 'socially': 1683, 'awkward': 171, 'buffoons': 269, 'free': 743, 'busses': 280, 'halls': 833, 'iffy': 916, 'wrong': 2060, 'bombarded': 234, 'crap': 448, 'elections': 602, 'riots': 1537, 'scandals': 1579, 'pandemics': 1312, 'climate': 367, 'enjoy': 618, 'childhood': 341, 'tackle': 1794, 'key': 1005, 'bringing': 258, 'interactions': 967, 'monitored': 1195, 'censored': 323, 'robot': 1543, 'exposed': 657, 'poisonous': 1374, 'pathetic': 1329, 'table': 1792, 'shift': 1632, 'visit': 1971, 'indoors': 953, 'tight': 1860, 'quarters': 1445, 'pcr': 1335, 'dollar': 556, 'researched': 1507, 'gain': 760, 'enhancements': 617, 'tried': 1904, 'renown': 1496, 'holding': 886, 'ransom': 1453, 'stricter': 1749, 'ummm': 1922, 'yellow': 2070, 'everywhere': 641, 'story': 1742, 'however': 902, 'arrived': 146, 'responsible': 1512, 'feardemia': 686, 'endangering': 612, 'toxins': 1885, 'exhaling': 649, 'produce': 1405, 'generation': 770, 'offence': 1271, 'globalism': 785, 'whole': 2018, 'doomed': 560, 'epidemic': 622, 'politics': 1379, 'dirtiest': 525, 'place': 1360, 'soap': 1681, 'bathrooms': 190, 'buses': 277, 'businesses': 279, 'due': 573, 'october': 1270, 'teens': 1818, 'strong': 1751, 'organize': 1299, 'healthy': 854, 'hiding': 873, 'behind': 204, 'doors': 562, 'tbh': 1810, 'writing': 2059, 'names': 1221, 'bcuz': 192, 'staying': 1731, 'wanted': 1986, 'comfortable': 382, '1or': 28, 'metre': 1168, 'wednesday': 2009, 'sanitizer': 1565, 'hour': 897, 'switch': 1786, 'economics': 587, 'arts': 150, 'music': 1211, 'washroom': 1992, 'sticker': 1734, 'stand': 1719, 'metres': 1169, 'nccla': 1226, '09082020': 3, 'offense': 1272, 'placed': 1361, 'saw': 1574, 'study': 1755, 'reveals': 1526, 'hydroxychloroquine': 909, 'vitamin': 1972, 'd3': 472, 'cure': 467, 'refuse': 1481, 'witnessed': 2034, 'talks': 1802, 'scarier': 1582, 'lice': 1061, 'society': 1684, 'gloom': 788, 'doom': 559, 'continually': 418, 'negatively': 1231, 'suicide': 1767, 'result': 1518, 'shutting': 1645, 'professionalism': 1406, 'anchor': 119, 'blinking': 228, 'pro': 1400, 'fearful': 687, 'conditioned': 405, 'brainwashed': 246, 'traumatized': 1896, 'technocratic': 1817, 'cabal': 283, 'governments': 806, 'leaders': 1042, 'trillions': 1906, 'profits': 1408, 'wealth': 2002, 'transfer': 1892, 'vaccinated': 1954, 'vaccination': 1955, 'records': 1473, 'mid': 1170, 'transmit': 1894, 'offered': 1273, 'distance': 545, 'medications': 1157, 'defective': 496, 'speak': 1700, 'stands': 1720, 'alone': 104, 'lisen': 1072, 'hitler': 881, 'mosas': 1200, 'intreast': 971, 'pauls': 1331, 'mans': 1128, 'gods': 794, 'age': 92, 'supports': 1774, 'attracts': 164, 'particles': 1321, 'water': 1999, 'creates': 452, 'existence': 651, 'travels': 1898, 'egg': 597, 'attract': 163, 'released': 1488, 'womb': 2037, 'teachings': 1814, 'sinful': 1658, 'default': 494, 'leaves': 1048, 'returns': 1524, 'gave': 767, 'dust': 576, 'invisible': 975, 'eye': 661, 'image': 924, 'moves': 1205, 'lungs': 1111, 'organ': 1298, 'constant': 415, 'movement': 1204, 'beyond': 214, 'manner': 1127, 'nature': 1224, 'witnessing': 2035, 'intellect': 966, 'corruptible': 431, 'corrected': 429, 'altered': 108, 'borne': 238, 'dies': 522, 'dependent': 505, 'upon': 1942, 'exist': 650, 'describes': 509, 'bible': 215, 'narrow': 1223, 'source': 1698, 'encounters': 609, 'untold': 1941, 'clarity': 357, 'topic': 1875, 'ganna': 762, 'shoooouuuld': 1634, 'borrowing': 239, 'america': 112, 'situations': 1662, 'progress': 1410, 'efforts': 596, 'negated': 1230, '370': 40, '000': 1, 'jk': 989, 'heck': 861, 'crooks': 461, 'household': 900, 'doe': 553, 'ricky': 1530, 'trailerpark': 1890, 'boys': 244, 'puppets': 1437, 'string': 1750, 'controlled': 423, 'goverment': 804, 'fascism': 678, 'insisting': 963, 'autonomy': 167, 'calls': 289, 'gathering': 765, 'tarred': 1805, 'feathered': 688, 'tf': 1833, 'doubt': 563, 'wan': 1983, 'houses': 901, 'dare': 477, 'suicidal': 1766, 'mission': 1185, 'incredibly': 943, 'disappointed': 528, 'satisfied': 1570, 'complainers': 396, 'accusing': 72, 'ignoring': 919, 'understands': 1930, 'took': 1873, 'favourite': 684, 'toy': 1886, 'karens': 1001, 'individuality': 950, 'descriptions': 510, 'sell': 1610, 'couple': 438, 'bound': 241, 'increasing': 942, 'program': 1409, 'remain': 1491, 'panic': 1314, '500': 47, 'overnight': 1305, 'lab': 1026, 'rats': 1458, 'compared': 394, 'hospitilizations': 895, 'sheeple': 1629, 'discussion': 534, 'tagged': 1796, 'automatically': 166, 'considered': 414, 'easy': 586, 'categorize': 312, 'antibody': 126, 'advise': 86, 'disliking': 544, 'globalnews': 787, 'thy': 1857, 'fix': 710, 'nightclubs': 1248, 'seem': 1604, 'smart': 1674, 'suffering': 1763, 'wont': 2040, 'vote': 1974, 'dictator': 518, 'mine': 1182, 'repent': 1498, 'accept': 68, 'saviour': 1573, 'receive': 1469, 'salvation': 1562, 'prosecuted': 1418, 'soundcloud': 1696, 'red': 1475, 'alert': 101, 'closest': 371, 'creatures': 455, 'cite': 352, 'immaterial': 927, 'goal': 791, 'porky': 1383, 'subjected': 1758, 'leave': 1047, 'permanent': 1346, 'scars': 1583, 'cv': 471, 'muzzling': 1214, 'depriving': 508, 'interactive': 968, 'grandma': 813, 'cruel': 462, 'heartless': 858, 'concerned': 404, 'chick': 339, 'sleep': 1667, 'giant': 778, 'bags': 178, 'rationales': 1457, 'consider': 413, 'academic': 66, 'freeze': 746, 'ignorant': 917, 'mistake': 1186, 'thinking': 1843, 'bet': 211, 'rich': 1527, 'afford': 90}\n"
     ]
    }
   ],
   "source": [
    "data = dataset\n",
    "\n",
    "\n",
    "data['polarity'] = data['comments'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data['pol_cat']  = 0\n",
    "\n",
    "data['pol_cat'][data.polarity > 0] = 1\n",
    "data['pol_cat'][data.polarity <= 0] = -1\n",
    "\n",
    "data_pos = data[data['pol_cat'] == 1]\n",
    "data_pos = data_pos.reset_index(drop = True)\n",
    "\n",
    "data_neg = data[data['pol_cat'] == -1]\n",
    "data_neg = data_neg.reset_index(drop = True)\n",
    "\n",
    "\n",
    "data['comments'] = data['comments'].str.lower()\n",
    "\n",
    "\n",
    "data['comments'][0].strip()\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data['comments'] = data['comments'].str.strip()\n",
    "\n",
    "train = data.copy()\n",
    "\n",
    "\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['stop_comments'] = data['comments'].apply(lambda x : remove_stopwords(x))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['stop_comments'],data['pol_cat'],test_size = 0.2,random_state = 324)\n",
    "vect = CountVectorizer()\n",
    "tf_train = vect.fit_transform(X_train)\n",
    "tf_test = vect.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(vect.vocabulary_)\n",
    "\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tf_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predicted = lr.predict(tf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968652037617555"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score on training dataset\n",
    "lr.score(tf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /opt/anaconda3/lib/python3.7/site-packages (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (1.18.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (3.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (0.23.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (49.3.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.7/site-packages (from mlxtend) (0.14.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.24.2->mlxtend) (2019.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121   1]\n",
      " [  0 197]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expected = y_train\n",
    "cf = metrics.confusion_matrix(expected,predicted,labels = [1,-1])\n",
    "print(cf)\n",
    "\n",
    "## this command is only for google collab \n",
    "## in the below figure \" 1 is actually showing -1 and 0 is actually showing 1\"\n",
    "fig, ax = plot_confusion_matrix(conf_mat = cf)\n",
    "                                \n",
    "## It canbe used in any platform\n",
    "# fig, ax = plot_confusion_matrix(conf_mat = cf, class_names = [1,-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1599668291360,
     "user": {
      "displayName": "Maryam Ahmadi",
      "photoUrl": "",
      "userId": "03531474721671310263"
     },
     "user_tz": 240
    },
    "id": "bru3tnL6iwBZ",
    "outputId": "79c24197-637f-44d1-a30d-9ebb8a45a90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negetive comments are more than Positive comments\n"
     ]
    }
   ],
   "source": [
    "data_pos =0\n",
    "data_neg = 0\n",
    "\n",
    "for i in range(0,len(predicted)):\n",
    "    if (predicted[i] == 1):\n",
    "        data_pos = data_pos + 1\n",
    "    else:\n",
    "        data_neg = data_neg + 1\n",
    "\n",
    "\n",
    "if (data_pos)>= (data_neg):\n",
    "    print (\"Positive comments are more than negetive comments\")\n",
    "elif (data_pos)== (data_neg):\n",
    "    print (\"positive comments and Negetive comments are equal \")\n",
    "else:\n",
    "    print(\"Negetive comments are more than Positive comments\")        \n",
    "        \n",
    "        \n",
    "# if (data_pos)>= (len(predicted)/3):\n",
    "#     print (\"Positive comments\")\n",
    "# elif (data_pos)== (len(predicted)/2):\n",
    "#     print (\"Not positive and Not negetive comments\")\n",
    "# else:\n",
    "#     print(\"Negetive comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "lr = lr\n",
    "Pkl_Filename = \"lr.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(lr, file)\n",
    "#...\n",
    "\n",
    "# save vect\n",
    "vect = vect\n",
    "Pkl_Filename = \"vect.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(vect, file)\n",
    "#...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /opt/anaconda3/lib/python3.7/site-packages (5.6.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (4.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (4.3.3)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (1.4.2)\n",
      "Requirement already satisfied: pygments in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (2.5.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (5.0.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (2.11.1)\n",
      "Requirement already satisfied: testpath in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (1.14.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (4.4.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (0.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (49.3.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (2.2.0)\n",
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvBFLM90qXmJ"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert 'Youtube comment analysis.ipynb' --to script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMh7YWlZBYLPkrty7JkrGs3",
   "collapsed_sections": [],
   "name": "Youtube comment analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
